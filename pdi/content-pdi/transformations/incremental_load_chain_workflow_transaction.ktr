<?xml version="1.0" encoding="UTF-8"?>
<transformation>
  <info>
    <name>incremental_load_chain_workflow_transaction</name>
    <description />
    <extended_description />
    <trans_version>1</trans_version>
    <trans_type>Normal</trans_type>
    <trans_status>0</trans_status>
    <directory>/</directory>
    <parameters>
      <parameter>
        <name>CHAIN_ID_SUFFIX</name>
        <default_value />
        <description />
      </parameter>
      <parameter>
        <name>CHAIN_TYPE</name>
        <default_value />
        <description />
      </parameter>
      <parameter>
        <name>CURRENT_CHAIN_ID</name>
        <default_value />
        <description />
      </parameter>
      <parameter>
        <name>ENV_SUFFIX</name>
        <default_value />
        <description />
      </parameter>
      <parameter>
        <name>SUB_ENV</name>
        <default_value />
        <description />
      </parameter>
    </parameters>
    <log>
      <trans-log-table>
        <connection />
        <schema />
        <table>${KETTLE_TRANS_LOG_TABLE}</table>
        <size_limit_lines />
        <interval />
        <timeout_days>${TRANSFORMATION_LOGS_RECORD_TIMEOUT}</timeout_days>
        <field>
          <id>ID_BATCH</id>
          <enabled>Y</enabled>
          <name>ID_BATCH</name>
        </field>
        <field>
          <id>CHANNEL_ID</id>
          <enabled>Y</enabled>
          <name>CHANNEL_ID</name>
        </field>
        <field>
          <id>TRANSNAME</id>
          <enabled>Y</enabled>
          <name>TRANSNAME</name>
        </field>
        <field>
          <id>STATUS</id>
          <enabled>Y</enabled>
          <name>STATUS</name>
        </field>
        <field>
          <id>LINES_READ</id>
          <enabled>Y</enabled>
          <name>LINES_READ</name>
          <subject />
        </field>
        <field>
          <id>LINES_WRITTEN</id>
          <enabled>Y</enabled>
          <name>LINES_WRITTEN</name>
          <subject />
        </field>
        <field>
          <id>LINES_UPDATED</id>
          <enabled>Y</enabled>
          <name>LINES_UPDATED</name>
          <subject />
        </field>
        <field>
          <id>LINES_INPUT</id>
          <enabled>Y</enabled>
          <name>LINES_INPUT</name>
          <subject />
        </field>
        <field>
          <id>LINES_OUTPUT</id>
          <enabled>Y</enabled>
          <name>LINES_OUTPUT</name>
          <subject />
        </field>
        <field>
          <id>LINES_REJECTED</id>
          <enabled>Y</enabled>
          <name>LINES_REJECTED</name>
          <subject />
        </field>
        <field>
          <id>ERRORS</id>
          <enabled>Y</enabled>
          <name>ERRORS</name>
        </field>
        <field>
          <id>STARTDATE</id>
          <enabled>Y</enabled>
          <name>STARTDATE</name>
        </field>
        <field>
          <id>ENDDATE</id>
          <enabled>Y</enabled>
          <name>ENDDATE</name>
        </field>
        <field>
          <id>LOGDATE</id>
          <enabled>Y</enabled>
          <name>LOGDATE</name>
        </field>
        <field>
          <id>DEPDATE</id>
          <enabled>Y</enabled>
          <name>DEPDATE</name>
        </field>
        <field>
          <id>REPLAYDATE</id>
          <enabled>Y</enabled>
          <name>REPLAYDATE</name>
        </field>
        <field>
          <id>LOG_FIELD</id>
          <enabled>Y</enabled>
          <name>LOG_FIELD</name>
        </field>
        <field>
          <id>EXECUTING_SERVER</id>
          <enabled>N</enabled>
          <name>EXECUTING_SERVER</name>
        </field>
        <field>
          <id>EXECUTING_USER</id>
          <enabled>N</enabled>
          <name>EXECUTING_USER</name>
        </field>
        <field>
          <id>CLIENT</id>
          <enabled>N</enabled>
          <name>CLIENT</name>
        </field>
      </trans-log-table>
      <perf-log-table>
        <connection />
        <schema />
        <table />
        <interval />
        <timeout_days />
        <field>
          <id>ID_BATCH</id>
          <enabled>Y</enabled>
          <name>ID_BATCH</name>
        </field>
        <field>
          <id>SEQ_NR</id>
          <enabled>Y</enabled>
          <name>SEQ_NR</name>
        </field>
        <field>
          <id>LOGDATE</id>
          <enabled>Y</enabled>
          <name>LOGDATE</name>
        </field>
        <field>
          <id>TRANSNAME</id>
          <enabled>Y</enabled>
          <name>TRANSNAME</name>
        </field>
        <field>
          <id>STEPNAME</id>
          <enabled>Y</enabled>
          <name>STEPNAME</name>
        </field>
        <field>
          <id>STEP_COPY</id>
          <enabled>Y</enabled>
          <name>STEP_COPY</name>
        </field>
        <field>
          <id>LINES_READ</id>
          <enabled>Y</enabled>
          <name>LINES_READ</name>
        </field>
        <field>
          <id>LINES_WRITTEN</id>
          <enabled>Y</enabled>
          <name>LINES_WRITTEN</name>
        </field>
        <field>
          <id>LINES_UPDATED</id>
          <enabled>Y</enabled>
          <name>LINES_UPDATED</name>
        </field>
        <field>
          <id>LINES_INPUT</id>
          <enabled>Y</enabled>
          <name>LINES_INPUT</name>
        </field>
        <field>
          <id>LINES_OUTPUT</id>
          <enabled>Y</enabled>
          <name>LINES_OUTPUT</name>
        </field>
        <field>
          <id>LINES_REJECTED</id>
          <enabled>Y</enabled>
          <name>LINES_REJECTED</name>
        </field>
        <field>
          <id>ERRORS</id>
          <enabled>Y</enabled>
          <name>ERRORS</name>
        </field>
        <field>
          <id>INPUT_BUFFER_ROWS</id>
          <enabled>Y</enabled>
          <name>INPUT_BUFFER_ROWS</name>
        </field>
        <field>
          <id>OUTPUT_BUFFER_ROWS</id>
          <enabled>Y</enabled>
          <name>OUTPUT_BUFFER_ROWS</name>
        </field>
      </perf-log-table>
      <channel-log-table>
        <connection />
        <schema />
        <table />
        <timeout_days />
        <field>
          <id>ID_BATCH</id>
          <enabled>Y</enabled>
          <name>ID_BATCH</name>
        </field>
        <field>
          <id>CHANNEL_ID</id>
          <enabled>Y</enabled>
          <name>CHANNEL_ID</name>
        </field>
        <field>
          <id>LOG_DATE</id>
          <enabled>Y</enabled>
          <name>LOG_DATE</name>
        </field>
        <field>
          <id>LOGGING_OBJECT_TYPE</id>
          <enabled>Y</enabled>
          <name>LOGGING_OBJECT_TYPE</name>
        </field>
        <field>
          <id>OBJECT_NAME</id>
          <enabled>Y</enabled>
          <name>OBJECT_NAME</name>
        </field>
        <field>
          <id>OBJECT_COPY</id>
          <enabled>Y</enabled>
          <name>OBJECT_COPY</name>
        </field>
        <field>
          <id>REPOSITORY_DIRECTORY</id>
          <enabled>Y</enabled>
          <name>REPOSITORY_DIRECTORY</name>
        </field>
        <field>
          <id>FILENAME</id>
          <enabled>Y</enabled>
          <name>FILENAME</name>
        </field>
        <field>
          <id>OBJECT_ID</id>
          <enabled>Y</enabled>
          <name>OBJECT_ID</name>
        </field>
        <field>
          <id>OBJECT_REVISION</id>
          <enabled>Y</enabled>
          <name>OBJECT_REVISION</name>
        </field>
        <field>
          <id>PARENT_CHANNEL_ID</id>
          <enabled>Y</enabled>
          <name>PARENT_CHANNEL_ID</name>
        </field>
        <field>
          <id>ROOT_CHANNEL_ID</id>
          <enabled>Y</enabled>
          <name>ROOT_CHANNEL_ID</name>
        </field>
      </channel-log-table>
      <step-log-table>
        <connection />
        <schema />
        <table />
        <timeout_days />
        <field>
          <id>ID_BATCH</id>
          <enabled>Y</enabled>
          <name>ID_BATCH</name>
        </field>
        <field>
          <id>CHANNEL_ID</id>
          <enabled>Y</enabled>
          <name>CHANNEL_ID</name>
        </field>
        <field>
          <id>LOG_DATE</id>
          <enabled>Y</enabled>
          <name>LOG_DATE</name>
        </field>
        <field>
          <id>TRANSNAME</id>
          <enabled>Y</enabled>
          <name>TRANSNAME</name>
        </field>
        <field>
          <id>STEPNAME</id>
          <enabled>Y</enabled>
          <name>STEPNAME</name>
        </field>
        <field>
          <id>STEP_COPY</id>
          <enabled>Y</enabled>
          <name>STEP_COPY</name>
        </field>
        <field>
          <id>LINES_READ</id>
          <enabled>Y</enabled>
          <name>LINES_READ</name>
        </field>
        <field>
          <id>LINES_WRITTEN</id>
          <enabled>Y</enabled>
          <name>LINES_WRITTEN</name>
        </field>
        <field>
          <id>LINES_UPDATED</id>
          <enabled>Y</enabled>
          <name>LINES_UPDATED</name>
        </field>
        <field>
          <id>LINES_INPUT</id>
          <enabled>Y</enabled>
          <name>LINES_INPUT</name>
        </field>
        <field>
          <id>LINES_OUTPUT</id>
          <enabled>Y</enabled>
          <name>LINES_OUTPUT</name>
        </field>
        <field>
          <id>LINES_REJECTED</id>
          <enabled>Y</enabled>
          <name>LINES_REJECTED</name>
        </field>
        <field>
          <id>ERRORS</id>
          <enabled>Y</enabled>
          <name>ERRORS</name>
        </field>
        <field>
          <id>LOG_FIELD</id>
          <enabled>N</enabled>
          <name>LOG_FIELD</name>
        </field>
      </step-log-table>
      <metrics-log-table>
        <connection />
        <schema />
        <table />
        <timeout_days />
        <field>
          <id>ID_BATCH</id>
          <enabled>Y</enabled>
          <name>ID_BATCH</name>
        </field>
        <field>
          <id>CHANNEL_ID</id>
          <enabled>Y</enabled>
          <name>CHANNEL_ID</name>
        </field>
        <field>
          <id>LOG_DATE</id>
          <enabled>Y</enabled>
          <name>LOG_DATE</name>
        </field>
        <field>
          <id>METRICS_DATE</id>
          <enabled>Y</enabled>
          <name>METRICS_DATE</name>
        </field>
        <field>
          <id>METRICS_CODE</id>
          <enabled>Y</enabled>
          <name>METRICS_CODE</name>
        </field>
        <field>
          <id>METRICS_DESCRIPTION</id>
          <enabled>Y</enabled>
          <name>METRICS_DESCRIPTION</name>
        </field>
        <field>
          <id>METRICS_SUBJECT</id>
          <enabled>Y</enabled>
          <name>METRICS_SUBJECT</name>
        </field>
        <field>
          <id>METRICS_TYPE</id>
          <enabled>Y</enabled>
          <name>METRICS_TYPE</name>
        </field>
        <field>
          <id>METRICS_VALUE</id>
          <enabled>Y</enabled>
          <name>METRICS_VALUE</name>
        </field>
      </metrics-log-table>
    </log>
    <maxdate>
      <connection />
      <table />
      <field />
      <offset>0.0</offset>
      <maxdiff>0.0</maxdiff>
    </maxdate>
    <size_rowset>10000</size_rowset>
    <sleep_time_empty>50</sleep_time_empty>
    <sleep_time_full>50</sleep_time_full>
    <unique_connections>Y</unique_connections>
    <feedback_shown>Y</feedback_shown>
    <feedback_size>50000</feedback_size>
    <using_thread_priorities>Y</using_thread_priorities>
    <shared_objects_file />
    <capture_step_performance>N</capture_step_performance>
    <step_performance_capturing_delay>1000</step_performance_capturing_delay>
    <step_performance_capturing_size_limit>100</step_performance_capturing_size_limit>
    <dependencies>
    </dependencies>
    <partitionschemas>
    </partitionschemas>
    <slaveservers>
    </slaveservers>
    <clusterschemas>
    </clusterschemas>
    <created_user>-</created_user>
    <created_date>2019/03/14 15:41:55.029</created_date>
    <modified_user>-</modified_user>
    <modified_date>2019/03/14 15:41:55.029</modified_date>
    <key_for_session_key>H4sIAAAAAAAAAAMAAAAAAAAAAAA=</key_for_session_key>
    <is_key_private>N</is_key_private>
  </info>
  <notepads>
  </notepads>
  <connection>
    <name>analytics_redshift_connection</name>
    <server />
    <type>REDSHIFT</type>
    <access>JNDI</access>
    <database>analyticsRedshiftConnection${ENV_SUFFIX}</database>
    <port>1521</port>
    <username />
    <password>Encrypted </password>
    <servername />
    <data_tablespace />
    <index_tablespace />
    <attributes>
      <attribute>
        <code>EXTRA_OPTION_REDSHIFT.tcpKeepAlive</code>
        <attribute>true</attribute>
      </attribute>
      <attribute>
        <code>FORCE_IDENTIFIERS_TO_LOWERCASE</code>
        <attribute>N</attribute>
      </attribute>
      <attribute>
        <code>FORCE_IDENTIFIERS_TO_UPPERCASE</code>
        <attribute>N</attribute>
      </attribute>
      <attribute>
        <code>IS_CLUSTERED</code>
        <attribute>N</attribute>
      </attribute>
      <attribute>
        <code>PORT_NUMBER</code>
        <attribute>1521</attribute>
      </attribute>
      <attribute>
        <code>PRESERVE_RESERVED_WORD_CASE</code>
        <attribute>Y</attribute>
      </attribute>
      <attribute>
        <code>QUOTE_ALL_FIELDS</code>
        <attribute>N</attribute>
      </attribute>
      <attribute>
        <code>SUPPORTS_BOOLEAN_DATA_TYPE</code>
        <attribute>Y</attribute>
      </attribute>
      <attribute>
        <code>SUPPORTS_TIMESTAMP_DATA_TYPE</code>
        <attribute>Y</attribute>
      </attribute>
      <attribute>
        <code>USE_POOLING</code>
        <attribute>N</attribute>
      </attribute>
    </attributes>
  </connection>
  <order>
    <hop>
      <from>get_last_process_time_for_chain</from>
      <to>load_all_workflows_transactions</to>
      <enabled>Y</enabled>
    </hop>
  </order>
  <step>
    <name>get_last_process_time_for_chain</name>
    <type>TableInput</type>
    <description />
    <distribute>Y</distribute>
    <custom_distribution />
    <copies>1</copies>
    <partitioning>
      <method>none</method>
      <schema_name />
    </partitioning>
    <connection>analytics_redshift_connection</connection>
    <sql>select max(value) as  last_processed_block_timestamp from
${PENTAHO_REDSHIFT_SCHEMA_PREFIX}_${SUB_ENV}${ENV_SUFFIX}.pentaho_processing_info
where property = ('last_processed_block_timestamp_' || '${CHAIN_TYPE}' ||  '${CHAIN_ID_SUFFIX}') limit 1;</sql>
    <limit>0</limit>
    <lookup />
    <execute_each_row>N</execute_each_row>
    <variables_active>Y</variables_active>
    <lazy_conversion_active>N</lazy_conversion_active>
    <attributes />
    <cluster_schema />
    <remotesteps>
      <input>
      </input>
      <output>
      </output>
    </remotesteps>
    <GUI>
      <xloc>240</xloc>
      <yloc>256</yloc>
      <draw>Y</draw>
    </GUI>
  </step>
  <step>
    <name>load_all_workflows_transactions</name>
    <type>ExecSQL</type>
    <description />
    <distribute>Y</distribute>
    <custom_distribution />
    <copies>1</copies>
    <partitioning>
      <method>none</method>
      <schema_name />
    </partitioning>
    <connection>analytics_redshift_connection</connection>
    <execute_each_row>Y</execute_each_row>
    <single_statement>N</single_statement>
    <replace_variables>Y</replace_variables>
    <quoteString>N</quoteString>
    <sql>set search_path= ${TEMP_PENTAHO_REDSHIFT_SCHEMA_PREFIX}_${SUB_ENV}${ENV_SUFFIX};

truncate temp_incremental_chain_transactions_${CHAIN_TYPE}${CHAIN_ID_SUFFIX};

insert into temp_incremental_chain_transactions_${CHAIN_TYPE}${CHAIN_ID_SUFFIX}
(select tx_hash,
        from_address,
        '${CHAIN_TYPE}' as chain_type,
      	${CURRENT_CHAIN_ID} as chain_id,
      	token_id::INTEGER,
      	kind as tx_kind,
      	block_timestamp,
      	(CASE (status = true AND status_internal = true)
         WHEN TRUE THEN 'success'
         ELSE 'fail'
          END) AS tx_status,
      	gas_price,
      	gas_used,
      	gas_limit
 from ${PRESTAGING_REDSHIFT_SCHEMA_PREFIX}_${SUB_ENV}${ENV_SUFFIX}.transactions_${CHAIN_TYPE}${CHAIN_ID_SUFFIX}
where block_timestamp &lt;= (select max(created_at) from ${PRESTAGING_REDSHIFT_SCHEMA_PREFIX}_${SUB_ENV}${ENV_SUFFIX}.workflows)
and block_timestamp > ?
);

truncate table temp_incremental_chain_workflow_transactions_${CHAIN_TYPE}${CHAIN_ID_SUFFIX};

insert into temp_incremental_chain_workflow_transactions_${CHAIN_TYPE}${CHAIN_ID_SUFFIX}
(select tx.tx_hash,
        tx.from_address,
        tx.chain_type,
      	tx.chain_id,
      	tx.token_id,
      	tx.tx_kind,
		(tx.block_timestamp - MOD(tx.block_timestamp,86400)::INTEGER) AS rounded_date_timestamp,
      	tx.tx_status,
      	tx.gas_price,
      	tx.gas_used,
      	tx.gas_limit,
		(tx.gas_price *tx.gas_used) as tx_fees,
		
		0 as workflow_id,
		500 as workflow_kind,
		tx.tx_status as workflow_status,
		(tx.block_timestamp - MOD(tx.block_timestamp,86400)::INTEGER) AS rounded_workflow_create_timestamp
		
 from  (select * from temp_incremental_chain_transactions_${CHAIN_TYPE}${CHAIN_ID_SUFFIX} 
where tx_kind in (54)) as tx
);

insert into temp_incremental_chain_workflow_transactions_${CHAIN_TYPE}${CHAIN_ID_SUFFIX}
(select tx.tx_hash,
        tx.from_address,
        tx.chain_type,
      	tx.chain_id,
      	tx.token_id,
      	tx.tx_kind,
		(tx.block_timestamp - MOD(tx.block_timestamp,86400)::INTEGER) AS rounded_date_timestamp,
      	tx.tx_status,
      	tx.gas_price,
      	tx.gas_used,
      	tx.gas_limit,
		(tx.gas_price *tx.gas_used) as tx_fees,
		
		coalesce(w.id,0) as workflow_id,
		coalesce(w.kind,0) as workflow_kind,
		case when w.status is null then tx.tx_status
			when w.status=1 then 'pending'
			when w.status=2 then 'success'
			when w.status=3 then 'fail'
			when w.status=4 then 'fail'
			end	as workflow_status,
		(coalesce(extract(epoch from w.created_at::DATE), (tx.block_timestamp - MOD(tx.block_timestamp,86400)::INTEGER))) AS rounded_workflow_create_timestamp		
 from  ( select * from temp_incremental_chain_transactions_${CHAIN_TYPE}${CHAIN_ID_SUFFIX} where tx_kind not in (54))as tx
left join ${PRESTAGING_REDSHIFT_SCHEMA_PREFIX}_${SUB_ENV}${ENV_SUFFIX}.workflow_steps as ws
on ws.transaction_hash = tx.tx_hash
left join ${PRESTAGING_REDSHIFT_SCHEMA_PREFIX}_${SUB_ENV}${ENV_SUFFIX}.workflows as w
on w.id = ws.workflow_id
);

truncate table temp_incremental_chain_workflow_transactions_sk_${CHAIN_TYPE}${CHAIN_ID_SUFFIX};
insert into temp_incremental_chain_workflow_transactions_sk_${CHAIN_TYPE}${CHAIN_ID_SUFFIX}
(select tx.tx_hash,
        tx.from_address,
		coalesce(ad.address_type_sk, 0) as from_address_type_sk,
        tx.chain_type,
      	tx.chain_id,
		tx.token_id,
      	coalesce(tok.token_sk, 0) as token_sk,
      	tx.tx_kind,
      	dtx.date_sk as tx_date_sk,
      	tx.tx_status,
      	tx.gas_price,
      	tx.gas_used,
      	tx.gas_limit,
		tx.tx_fees,
		
		workflow_id,
		coalesce(w.workflow_kind_sk, 0) as workflow_kind_sk,
		workflow_kind,
		workflow_status,
	 	rounded_workflow_create_timestamp,
		dw.date_sk as workflow_date_sk
		
 from  temp_incremental_chain_workflow_transactions_${CHAIN_TYPE}${CHAIN_ID_SUFFIX} as tx
 left join ${PENTAHO_REDSHIFT_SCHEMA_PREFIX}_${SUB_ENV}${ENV_SUFFIX}.workflow_addresses ad
	on ad.address = tx.from_address
 left join ${PENTAHO_REDSHIFT_SCHEMA_PREFIX}_${SUB_ENV}${ENV_SUFFIX}.dim_tokens tok
	on tok.token_id = tx.token_id
 join ${PENTAHO_REDSHIFT_SCHEMA_PREFIX}_${SUB_ENV}${ENV_SUFFIX}.dim_dates dtx
	on dtx.timestamp = tx.rounded_date_timestamp
 join ${PENTAHO_REDSHIFT_SCHEMA_PREFIX}_${SUB_ENV}${ENV_SUFFIX}.dim_dates dw
	on dw.timestamp = tx.rounded_workflow_create_timestamp
 left join ${PENTAHO_REDSHIFT_SCHEMA_PREFIX}_${SUB_ENV}${ENV_SUFFIX}.dim_workflow_kinds w
	on w.kind = tx.workflow_kind
);

insert into ${PENTAHO_REDSHIFT_SCHEMA_PREFIX}_${SUB_ENV}${ENV_SUFFIX}.all_workflows_transactions
(
select *, extract(epoch from GETDATE()) as last_updated_at from temp_incremental_chain_workflow_transactions_sk_${CHAIN_TYPE}${CHAIN_ID_SUFFIX}
);

update ${PENTAHO_REDSHIFT_SCHEMA_PREFIX}_${SUB_ENV}${ENV_SUFFIX}.pentaho_processing_info
set value = GREATEST(value, (select coalesce(max(block_timestamp), 0) from temp_incremental_chain_transactions_${CHAIN_TYPE}${CHAIN_ID_SUFFIX}))
where property=('last_processed_block_timestamp_' || '${CHAIN_TYPE}' || '${CHAIN_ID_SUFFIX}');</sql>
    <set_params>N</set_params>
    <insert_field />
    <update_field />
    <delete_field />
    <read_field>insert_stat</read_field>
    <arguments>
      <argument>
        <name>last_processed_block_timestamp</name>
      </argument>
    </arguments>
    <attributes />
    <cluster_schema />
    <remotesteps>
      <input>
      </input>
      <output>
      </output>
    </remotesteps>
    <GUI>
      <xloc>512</xloc>
      <yloc>272</yloc>
      <draw>Y</draw>
    </GUI>
  </step>
  <step_error_handling>
  </step_error_handling>
  <slave-step-copy-partition-distribution>
  </slave-step-copy-partition-distribution>
  <slave_transformation>N</slave_transformation>
  <attributes />
</transformation>
